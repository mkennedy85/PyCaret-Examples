{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret Time Series Forecasting Tutorial\n",
    "\n",
    "**Dataset:** Hourly Energy Consumption  \n",
    "**Source:** Kaggle - US Energy Consumption Data  \n",
    "**Task:** Forecast future energy consumption using time series models\n",
    "\n",
    "---\n",
    "\n",
    "## What is Time Series Forecasting?\n",
    "\n",
    "Time series forecasting predicts future values based on historical data points collected over time. This tutorial demonstrates:\n",
    "\n",
    "- **ARIMA** - AutoRegressive Integrated Moving Average\n",
    "- **Prophet** - Facebook's forecasting model\n",
    "- **Exponential Smoothing** - Traditional forecasting\n",
    "- **Seasonal Decomposition** - Understanding trends and patterns\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "import pycaret\n",
    "print(f\"PyCaret version: {pycaret.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "The energy consumption dataset contains hourly power usage data.  \n",
    "We'll use this to forecast future energy demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load energy consumption dataset\n",
    "# Note: The dataset may have multiple CSV files for different regions\n",
    "data_dir = Path('../datasets/timeseries')\n",
    "csv_files = list(data_dir.glob('*.csv'))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for f in csv_files:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Load the first dataset (you can change this to load a different region)\n",
    "df = pd.read_csv(csv_files[0])\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Prepare the time series data for forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data types and missing values\n",
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset typically has a 'Datetime' column and energy consumption values\n",
    "# Let's identify the datetime and value columns\n",
    "\n",
    "# Find datetime column (usually contains 'date' or 'time')\n",
    "date_col = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()][0]\n",
    "print(f\"Datetime column: {date_col}\")\n",
    "\n",
    "# Find value column (usually numeric, not datetime)\n",
    "value_cols = [col for col in df.columns if col != date_col and df[col].dtype in ['float64', 'int64']]\n",
    "value_col = value_cols[0]  # Use first numeric column\n",
    "print(f\"Value column: {value_col}\")\n",
    "\n",
    "# Convert datetime column to datetime type\n",
    "df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "# Create a clean dataframe with just datetime and value\n",
    "ts_df = df[[date_col, value_col]].copy()\n",
    "ts_df.columns = ['date', 'value']\n",
    "\n",
    "# Handle missing values\n",
    "if ts_df['value'].isnull().any():\n",
    "    print(f\"\\nFilling {ts_df['value'].isnull().sum()} missing values...\")\n",
    "    ts_df['value'] = ts_df['value'].fillna(method='ffill')\n",
    "\n",
    "print(f\"\\nCleaned dataset shape: {ts_df.shape}\")\n",
    "print(f\"Date range: {ts_df['date'].min()} to {ts_df['date'].max()}\")\n",
    "ts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts_df['date'], ts_df['value'], linewidth=0.5)\n",
    "plt.title(f'{value_col} Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(value_col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a smaller subset for faster training (last 6 months)\n",
    "# This avoids Dask compatibility issues with large datasets\n",
    "cutoff_date = ts_df['date'].max() - pd.DateOffset(months=6)\n",
    "ts_df_subset = ts_df[ts_df['date'] >= cutoff_date].reset_index(drop=True)\n",
    "\n",
    "# Further reduce to max 5000 rows if still too large\n",
    "if len(ts_df_subset) > 5000:\n",
    "    ts_df_subset = ts_df_subset.iloc[-5000:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Using subset: {ts_df_subset.shape[0]} records\")\n",
    "print(f\"Date range: {ts_df_subset['date'].min()} to {ts_df_subset['date'].max()}\")\n",
    "\n",
    "# Plot subset\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts_df_subset['date'], ts_df_subset['value'])\n",
    "plt.title('Energy Consumption (Recent Subset)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(value_col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret Setup\n",
    "\n",
    "Initialize time series forecasting with PyCaret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.time_series import *\n",
    "\n",
    "# Setup time series experiment\n",
    "# fh = forecast horizon (how many periods ahead to forecast)\n",
    "# For hourly data, fh=24 means forecast 1 day ahead\n",
    "# Using smaller forecast horizon due to limited data\n",
    "\n",
    "ts_setup = setup(\n",
    "    data=ts_df_subset,\n",
    "    target='value',\n",
    "    fh=24,  # Forecast 1 day ahead (24 hours) - reduced from 168 for smaller dataset\n",
    "    fold=3,  # Reduced from default 10 for faster execution\n",
    "    session_id=42,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Compare multiple time series forecasting models automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all available models\n",
    "# This may take a while depending on data size\n",
    "best_models = compare_models(n_select=3, sort='MAPE')  # Select top 3 by MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Individual Models\n",
    "\n",
    "Let's train specific models for detailed analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prophet Model\n",
    "\n",
    "Facebook's Prophet handles seasonality and trends well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prophet model\n",
    "prophet = create_model('prophet')\n",
    "print(prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet forecast\n",
    "plot_model(prophet, plot='forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet components (trend, seasonality)\n",
    "plot_model(prophet, plot='decomp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Auto ARIMA\n",
    "\n",
    "Automatic ARIMA finds optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Auto ARIMA model\n",
    "arima = create_model('auto_arima')\n",
    "print(arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA forecast\n",
    "plot_model(arima, plot='forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exponential Smoothing\n",
    "\n",
    "Classic exponential smoothing for time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Exponential Smoothing model\n",
    "ets = create_model('ets')\n",
    "print(ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ETS forecast\n",
    "plot_model(ets, plot='forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "Tune the best model for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the best model from compare_models\n",
    "best_model = best_models[0]\n",
    "tuned_model = tune_model(best_model)\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Future Values\n",
    "\n",
    "Generate predictions for the forecast horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecast\n",
    "forecast_df = predict_model(tuned_model)\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast with confidence intervals\n",
    "plot_model(tuned_model, plot='forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "plot_model(tuned_model, plot='residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot diagnostics\n",
    "plot_model(tuned_model, plot='diagnostics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in-sample vs out-of-sample\n",
    "plot_model(tuned_model, plot='insample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize and Save Model\n",
    "\n",
    "Finalize the best model and save for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize model (train on full dataset)\n",
    "final_model = finalize_model(tuned_model)\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save_model(final_model, '../outputs/timeseries/forecast_model')\n",
    "print(\"Model saved to: ../outputs/timeseries/forecast_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save forecast results\n",
    "forecast_df.to_csv('../outputs/timeseries/forecast_results.csv', index=False)\n",
    "print(\"Forecast saved to: ../outputs/timeseries/forecast_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Use Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load saved model and make predictions\n",
    "loaded_model = load_model('../outputs/timeseries/forecast_model')\n",
    "new_forecast = predict_model(loaded_model)\n",
    "print(new_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we:\n",
    "\n",
    "1. ✅ Loaded hourly energy consumption data\n",
    "2. ✅ Preprocessed time series data\n",
    "3. ✅ Visualized temporal patterns\n",
    "4. ✅ Compared multiple forecasting models\n",
    "5. ✅ Trained Prophet, ARIMA, and ETS models\n",
    "6. ✅ Tuned the best model\n",
    "7. ✅ Generated forecasts with confidence intervals\n",
    "8. ✅ Evaluated model diagnostics\n",
    "9. ✅ Saved models and forecasts\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Prophet** works well for data with strong seasonal patterns\n",
    "- **Auto ARIMA** automatically finds optimal ARIMA parameters\n",
    "- **Exponential Smoothing** is fast and effective for simple trends\n",
    "- PyCaret's `compare_models()` automatically evaluates multiple algorithms\n",
    "- The forecast horizon (`fh`) determines how far ahead to predict\n",
    "- Model diagnostics help identify issues with forecasts\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different forecast horizons (fh parameter)\n",
    "- Experiment with external regressors (weather, holidays, etc.)\n",
    "- Test models on different regions/datasets\n",
    "- Deploy model for real-time energy demand forecasting\n",
    "- Implement ensemble methods for improved accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
